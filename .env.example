# ConstructAI Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
APP_NAME=ConstructAI
DEBUG=false
HOST=0.0.0.0
PORT=8000

# =============================================================================
# DATABASE
# =============================================================================
# SQLite (default)
DATABASE_URL=sqlite:///./constructai.db

# PostgreSQL (production)
# DATABASE_URL=postgresql://user:password@localhost:5432/constructai

# =============================================================================
# SECURITY
# =============================================================================
SECRET_KEY=your-secret-key-change-in-production
API_KEY_ENABLED=false

# =============================================================================
# RATE LIMITING
# =============================================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=60

# =============================================================================
# LOGGING
# =============================================================================
LOG_LEVEL=INFO
# LOG_FILE=logs/constructai.log

# =============================================================================
# CORS
# =============================================================================
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# =============================================================================
# FILE UPLOAD
# =============================================================================
MAX_UPLOAD_SIZE_MB=50

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================

# Primary AI Provider (openai, azure, local)
AI_PRIMARY_PROVIDER=openai

# Fallback providers (comma-separated, in order of preference)
AI_FALLBACK_PROVIDERS=openai

# -----------------------------------------------------------------------------
# OPENAI CONFIGURATION
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Available models:
# - gpt-4o (recommended, latest, multimodal)
# - gpt-4o-mini (fast, cheap, good for most tasks)
# - gpt-4-turbo (powerful, expensive)
# - gpt-4 (original GPT-4)
# - gpt-3.5-turbo (legacy, cheapest)
OPENAI_MODEL=gpt-4o-mini

# Optional: Custom API base URL (for Azure OpenAI or proxies)
# OPENAI_API_BASE=https://your-custom-endpoint.com/v1

# Model parameters
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7

# -----------------------------------------------------------------------------
# AZURE OPENAI CONFIGURATION (Optional)
# -----------------------------------------------------------------------------
# For Azure OpenAI, use the OpenAI configuration with Azure-specific values
# OPENAI_API_KEY=your-azure-api-key
# OPENAI_API_BASE=https://your-resource.openai.azure.com
# OPENAI_API_VERSION=2024-02-15-preview
# OPENAI_MODEL=your-deployment-name

# -----------------------------------------------------------------------------
# LOCAL MODEL CONFIGURATION (Optional - Ollama)
# -----------------------------------------------------------------------------
# For running local models with Ollama
# LOCAL_API_BASE=http://localhost:11434
# LOCAL_MODEL=llama2
# LOCAL_MAX_TOKENS=4096
# LOCAL_TEMPERATURE=0.7

# =============================================================================
# AI FEATURES CONFIGURATION
# =============================================================================

# Enable/disable specific AI features
AI_RISK_PREDICTION_ENABLED=true
AI_COST_ESTIMATION_ENABLED=true
AI_RECOMMENDATIONS_ENABLED=true

# Model selection for specific tasks (optional, defaults to primary)
# AI_RISK_PREDICTION_PROVIDER=openai
# AI_COST_ESTIMATION_PROVIDER=anthropic
# AI_RECOMMENDATIONS_PROVIDER=openai

# =============================================================================
# REDIS (Optional - for caching)
# =============================================================================
# REDIS_URL=redis://localhost:6379/0
# REDIS_CACHE_TTL=3600

# =============================================================================
# CELERY (Optional - for background jobs)
# =============================================================================
# CELERY_BROKER_URL=redis://localhost:6379/1
# CELERY_RESULT_BACKEND=redis://localhost:6379/2
